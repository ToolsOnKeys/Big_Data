# 机器学习

## 1、机器学习主要分类

* 有监督学习：提供数据并提供数据对应地结果地机器学习过程
* 无监督学习：提供数据并且不提供数据对应结果地机器学习过程
* 强化学习：通过与环境交互并获取延迟返回进而改进行为地学习过程

## 2、有监督学习和无监督学习

### ①、无监督学习

* 无监督学习算法采用一组仅包含输入地数据，通过寻找数据中地内在结构来进行样本点地分组或聚类
* 算法从没有被标记或分类地测试数据中学习
* 无监督学习算法不是响应反馈，而是要识别数据中地共性特征；对于一个新数据，可以通过判断其中是否存在这种特征，来做出响应地反馈。
* 无监督学习地核心应用是统计学中地密度估计或聚类分析

### ②、监督学习

* 监督学习算法构建了包含输入和所需输出地一组数据地数学模型。这些数据称为训练数据，有一组训练样本组成。
* 监督学习主要包括分类和回归
* 单输出被限制为有限地一组值（离散数组）时使用地分类算法；当输出可以具有范围内地任意数值（连续数值）时使用回归算法。
* 相似度学习是和回归和分类都密切相关地一类监督机器学习，它的目标是使用相似性函数从样本中学习，这个函数可以度量两个对象之间地相似度或关联度。他在排名、推荐系统、视觉识别跟踪、人脸识别等方面有很好地应用场景。

#### Ⅰ、监督学习的三要素

* 模型：总结数据的内在规律，用数学函数描述的系统
* 策略：选取最优模型的评价准则
* 算法：选取最优模型的具体方法

#### Ⅱ、监督学习的实现步骤

* 得到一个有限的训练数据集
* 确定包含所有学习模型的集合
* 确定模型选择的准则，也就是学习策略
* 时下求解最优模型的算法，也就是学习算法
* 通过学习算法选择最优模型
* 利用得到的最优模型，对新数据进行预测或分析

#### Ⅲ、训练集和测试集

* 我们将数据输入到模型中训练出了对应模型
* 我们将用来训练模型的数据称为训练集，将用来测试模型好坏的数据称为测试集
* 训练集：输入到模型中对模型进行训练的数据集合
* 测试集：模型训练完成后测试训练效果的数据集合

#### Ⅳ、损失函数

* 损失函数用来衡量模型预测误差的大小

* 定义：选取模型f为决策函数，对于给定的输入参数X，f(X)为预测结果，Y为正式结果；f(X)与Y之间可能存在偏差，我们就用一个损失函数来度量预测偏差的程度，记作L(Y,f(X))

* 损失函数是系数的函数

* 损失函数值越小，模型就越好

  ```
  * 0-1损失函数
  * 平方损失函数
  * 绝对损失函数
  * 对数损失函数
  ```

#### Ⅴ、经验风险

* 经验风险：模型f(X)关于训练数据集的平均损失称为经验风险（empirial risk）

* 经验风险最小化（ERM）
  * 这一策略认为，经验风险最小的模型就是最优模型
  * 样本足够大时，ERM有很好的学习效果，因为足够多的经验
  * 样本较小时，ERM就会出现问题

#### Ⅵ、训练误差和测试误差

* 训练误差：关于数据集的平均损失；训练误差的大小，可以用来判断给定问题是否容易学习，但本质上并不重要
* 测试误差：时关于测试集的平均损失；测试误差真正反映了模型对位置数据的预测能力，这种能力被称为泛化能力

#### Ⅶ、过拟合和欠拟合

* 过拟合：把训练数据学习的太彻底，以至于把噪声数据的特征也学习到了，特征集过大，这样就会导致在后期测试的时候不能够很好的识别到数据，即不能正确的分类，模型泛化能力太差，称之为过拟合

* 模型的选择：当模型复杂度增大时，训练误差会组件减少并趋向于0；而测试误差会先减小，达到最小值之后再增大；当模型复杂度过大时，就会发生过拟合，所以模型复杂度要适当

#### Ⅷ、正则化

* 结构风险最小化：是在ERM基础上，为了防止过拟合提出来的策略；再经验风险上加上表示模型复杂度的正则化项，或者叫惩罚项；正则化项一般时模型复杂度的单调递增函数，即模型越复杂，正则化值越大。

#### Ⅸ、交叉验证

* 数据集划分：如果样本数据充足，一种简单方法时随机将数据集且分成三部分：训练集，验证集，测试集
* 训练集用于训练模型，验证集用于模型选择，测试集用于学习方法评估
* 数据不充足时，可以重复的利用数据-交叉验证

## 3、分类和回归

* 监督学习的问题主要分为两类，即分类问题和回归问题
  * 分类问题预测问题属于哪一类-离散
  * 回顾问题根据数据预测一个值-连续

### ①、分类问题

* 再监督学习中，当输出变量Y取有限个离散值，预测问题就成为了分类问题
* 监督学习从数据中学习一个分类模型或分类决策函数，称为分类器；分类器对新的输入进行预测，称为分类
* 分类问题