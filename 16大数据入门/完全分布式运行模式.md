# 完全分布式运行模式

## 分析

>1、准备三台客户机（克隆+调整ip和主机名称）
>
>2、安装JDK（2-4步可以通过编写一个群发的脚本xsync，从一台已安装的主机上将JDK和Hadoop群发给三个主机，同时将配置文件也通过群发的方式同步到三个主机中）
>
>3、配置环境变量
>
>4、安装Hadoop
>
>5、配置环境变量
>
>6、配置集群
>
>7、单点启动
>
>8、配置ssh
>
>9、群起并测试集群

## Ⅰ 编写集群分发脚本

### 1、scp 安全拷贝

* 定义：可以实现服务器与服务器之间的数据拷贝

* 基本语法：

  ``` shell
  scp -r 要拷贝文件路径/名称 目的用户@主机：目的路径/名称
  注：-r 表示递归
  ```

### 2、rsync 远程同步工具

* 用途：主要用于备份和镜像。具有速度快、避免复制相同的内容和支持符号链接的优点

* rsync和scp的区别：用rsync做文件的复制要比scp的速度块，rsync支队差异文件做更新。scp是把所有的文件都复制过去

* 基本语法

  ``` shell
  rsync -rvl 要拷贝的文件路径/名称 目的用户@主机：目的路径/名称
  注：
     -r递归
     -v显示复制的过程
     -l拷贝符号链接
  ```

### 3、集群分发脚本 xsync

``` shell
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if((pcount==0)); then
echo no args;
exit;
fi
#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname
#3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir
#4 获取当前用户名称
user=`whoami`
#5 循环
for((host=103; host<105; host++)); do
        echo ------------------- hadoop$host --------------
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done
```

## Ⅱ 集群配置

|      |     hadoop101     |           hadoop102           |          hadoop103           |
| ---- | :---------------: | :---------------------------: | :--------------------------: |
| HDFS | NameNode DataNode |           DataNode            | SecondaryNameNode   DataNode |
| YARN |    NodeManager    | ResourceManager   NodeManager |         NodeManager          |

### 1、核心配置文件 core-site.xml

```xml
<!-- 指定HDFS中NameNode的地址 -->
<property>
		<name>fs.defaultFS</name>
      <value>hdfs://hadoop101:9000</value>
</property>

<!-- 指定Hadoop运行时产生文件的存储目录 -->
<property>
		<name>hadoop.tmp.dir</name>
		<value>/opt/module/hadoop-2.7.2/data/tmp</value>
</property>

```

### 2、HDFS 配置文件

* 配置Hadoop-env.sh

  ``` sh
  export JAVA_HOME=/opt/module/jdk1.8.0_144
  ```

* 配置hdfs-site.xml

  ``` xml
  <!-- 指定几个副本 -->
  <property>
  		<name>dfs.replication</name>
  		<value>3</value>
  </property>
  
  <!-- 指定Hadoop辅助名称节点主机配置 -->
  <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop103:50090</value>
  </property>
  
  ```

### 3、YARN 配置文件

* 配置yarn-env.sh

  ``` sh
  export JAVA_HOME=/opt/module/jdk1.8.0_144
  ```

* 配置yarn-site.xml

  ``` xml
  <!-- Reducer获取数据的方式 -->
  <property>
  		<name>yarn.nodemanager.aux-services</name>
  		<value>mapreduce_shuffle</value>
  </property>
  
  <!-- 指定YARN的ResourceManager的地址 -->
  <property>
  		<name>yarn.resourcemanager.hostname</name>
  		<value>hadoop102</value>
  </property>
  ```

### 4、MapReduce 配置文件

* 配置mapred-env.sh

  ``` sh
  export JAVA_HOME=/opt/module/jdk1.8.0_144
  ```

* 配置mapred-site.xml

  > cp mapred-site.xml.template mapred-site.xml

  ``` xml
  <!-- 指定MR运行在Yarn上 -->
  <property>
  		<name>mapreduce.framework.name</name>
  		<value>yarn</value>
  </property>
  ```

  

## Ⅲ 集群上分发Hadoop配置文件

``` Linux
 xsync /opt/module/hadoop-2.7.2/etc/hadoop
```

## Ⅳ 集群启动

### 1、集群单点启动（不推荐使用）

* 第一次启动时，需要格式化NameNode

  ``` linux
  hadoop namenode -format
  ```

* NameNode启动

  ``` linux
  sbin/hadoop-daemon.sh start namenode
  ```

* DataNode启动

  ``` linux
  sbin/hadoop-daemon.sh start datanode
  ```

* secondarynode启动

  ``` linux
  sbin/hadoop-daemon.sh start secondarynode
  ```

### 2、群起集群（推荐）

#### ①、SSH无密登陆配置

* 服务器切换

  ```linux
  ssh 切换的目的主机ip
  ```

* 生成公钥和私钥

  ``` linux
  ssh-keygen -t rsa
  ```

* 将公钥copy到要免密登陆的目标主机上

  ``` linux
  ssh-copy-id 目标主机ip
  ```

#### ②、群起集群

* 配置slaves -> vim slaves

  ``` 
  hadoop101
  hadoop102
  hadoop103
  ```

* 群发slaves

  ``` linux
  xsync slaves
  ```

* 启动集群

  > 1、如果第一次启动需要格式化NameNode：bin/hdfs namenode -format
  >
  > 2、启动HDFS：sbin/start-dfs.sh
  >
  > 3、启动YARN：sbin/start-yarn.sh

## Ⅴ 配置日志的集聚

* 配置mapred.site.xml

  ```
  <!-- 历史服务器端地址 -->
  <property>
  <name>mapreduce.jobhistory.address</name>
  <value>hadoop102:10020</value>
  </property>
  <!-- 历史服务器web端地址 -->
  <property>
      <name>mapreduce.jobhistory.webapp.address</name>
      <value>hadoop102:19888</value>
  </property>
  ```

* 配置yarn-site.xml

  ```xml
  <!-- 日志聚集功能使能 -->
  <property>
  <name>yarn.log-aggregation-enable</name>
  <value>true</value>
  </property>
  <!-- 日志保留时间设置7天 -->
  <property>
  <name>yarn.log-aggregation.retain-seconds</name>
  <value>604800</value>
  </property>
  ```

* 群发日志配置文件yarn-site.xml

  ``` linux
  xsync yarn-site.xml
  ```

* 重启yarn配置和historymanager

  ``` linux
  sbin/stop-yarn.sh
  sbin/start-yarn.sh
  sbin/mr-jobhistory-daemon.sh stop historyserver
  sbin/mr-jobhistory-daemon.sh start historyserver
  ```

* 查看日志方式：

  ``` web
  http://hadoop101:19888/jobhistory
  ```

## Ⅵ 常用的几个网址说明

### 1、web端查看HDFS文件系统

``` web
①、查看namenode上的信息
http://hadoop101:50070/dfshealth.html#tab-overview
注：hadoop101为NameNode设置点

②、查看secondarynode的状态信息
http://hadoop203:50090/status.html
```

![](D:\BigData\BigData\16大数据入门\相关说明图片\namenode.png)

![](D:\BigData\BigData\16大数据入门\相关说明图片\secondarynode.png)

### 2、web端查看YARN即All Applications

``` web
http://hadoop102:8088/cluster
注：hadoop102为SourceManager的设置点
```

![](D:\BigData\BigData\16大数据入门\相关说明图片\yarn-all_applications.png)

### 3、web端查看JobHistory

``` web
http://hadoop101:19888/jobhistory
```

![](D:\BigData\BigData\16大数据入门\相关说明图片\jobhistory.png)